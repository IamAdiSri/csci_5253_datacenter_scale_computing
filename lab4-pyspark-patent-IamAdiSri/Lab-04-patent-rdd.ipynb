{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCI 4253 / 5253 - Lab #4 - Patent Problem with Spark RDD - SOLUTION\n",
    "<div>\n",
    " <h2> CSCI 4283 / 5253 \n",
    "  <IMG SRC=\"https://www.colorado.edu/cs/profiles/express/themes/cuspirit/logo.png\" WIDTH=50 ALIGN=\"right\"/> </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This [Spark cheatsheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/PySpark_SQL_Cheat_Sheet_Python.pdf) is useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "import numpy as np\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf=SparkConf().setAppName(\"Lab4-rdd\").setMaster(\"local[*]\")\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using PySpark and RDD's on the https://coding.csel.io machines is slow -- most of the code is executed in Python and this is much less efficient than the java-based code using the PySpark dataframes. Be patient and trying using `.cache()` to cache the output of joins. You may want to start with a reduced set of data before running the full task. You can use the `sample()` method to extract just a sample of the data or use "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two RDD's are called \"rawCitations\" and \"rawPatents\" because you probably want to process them futher (e.g. convert them to integer types, etc). \n",
    "\n",
    "The `textFile` function returns data in strings. This should work fine for this lab.\n",
    "\n",
    "Other methods you use might return data in type `Byte`. If you haven't used Python `Byte` types before, google it. You can convert a value of `x` type byte into e.g. a UTF8 string using `x.decode('uft-8')`. Alternatively, you can use the `open` method of the gzip library to read in all the lines as UTF-8 strings like this:\n",
    "```\n",
    "import gzip\n",
    "with gzip.open('cite75_99.txt.gz', 'rt',encoding='utf-8') as f:\n",
    "    rddCitations = sc.parallelize( f.readlines() )\n",
    "```\n",
    "This is less efficient than using `textFile` because `textFile` would use the underlying HDFS or other file system to read the file across all the worker nodes while the using `gzip.open()...readlines()` will read all the data in the frontend and then distribute it to all the worker nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rddCitations = sc.textFile(\"cite75_99.txt.gz\")\n",
    "rddPatents = sc.textFile(\"apat63_99.txt.gz\")\n",
    "# rddPatents = sc.textFile(\"apat63_99.txt.gz\").sample(fraction=.003, withReplacement=False, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data looks like the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"CITING\",\"CITED\"',\n",
       " '3858241,956203',\n",
       " '3858241,1324234',\n",
       " '3858241,3398406',\n",
       " '3858241,3557384']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddCitations.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"PATENT\",\"GYEAR\",\"GDATE\",\"APPYEAR\",\"COUNTRY\",\"POSTATE\",\"ASSIGNEE\",\"ASSCODE\",\"CLAIMS\",\"NCLASS\",\"CAT\",\"SUBCAT\",\"CMADE\",\"CRECEIVE\",\"RATIOCIT\",\"GENERAL\",\"ORIGINAL\",\"FWDAPLAG\",\"BCKGTLAG\",\"SELFCTUB\",\"SELFCTLB\",\"SECDUPBD\",\"SECDLWBD\"',\n",
       " '3070801,1963,1096,,\"BE\",\"\",,1,,269,6,69,,1,,0,,,,,,,',\n",
       " '3070802,1963,1096,,\"US\",\"TX\",,1,,2,6,63,,0,,,,,,,,,',\n",
       " '3070803,1963,1096,,\"US\",\"IL\",,1,,2,6,63,,9,,0.3704,,,,,,,',\n",
       " '3070804,1963,1096,,\"US\",\"OH\",,1,,2,6,63,,3,,0.6667,,,,,,,']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddPatents.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, they are a single string with multiple CSV's. You will need to convert these to (K,V) pairs, probably convert the keys to `int` and so on. You'll need to `filter` out the header string as well since there's no easy way to extract all the lines except the first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method\n",
    "\n",
    "1. Join patents with citations to retrieve all of each patent's citations.\n",
    "2. Join this rdd back with patents to now retrieve each citation's postate.\n",
    "3. Filter out rows where the citing postate matches the citated poststate.\n",
    "4. Group these rows by their citing patent number to find cocitations, and count said cocitations.\n",
    "5. Join the counts back to patents to get output in required form and sort the rows in descending order of counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess rows to split fields\n",
    "patents = rddPatents.map(lambda x: x.split(\",\")).cache()\n",
    "citations = rddCitations.map(lambda x: x.split(\",\")).cache()\n",
    "\n",
    "# save headers\n",
    "patents_header = patents.first()\n",
    "citations_header = citations.first()\n",
    "\n",
    "# remove headers from rdd\n",
    "patents = patents.filter(lambda row: row != patents_header)\n",
    "citations = citations.filter(lambda row: row != citations_header).cache()\n",
    "\n",
    "# filter out rows without POSTATE\n",
    "patents = patents.filter(lambda r: r[5]!='\"\"').cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make key value pairs\n",
    "key_patents = patents.map(lambda r: (r[0], ','.join(r)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join with citations\n",
    "nq1 = key_patents.join(citations).cache()\n",
    "# parse and reformat\n",
    "parsed_nq1 = nq1.map(lambda r: r[1][0].split(',') + [r[1][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make key value pairs\n",
    "key_nq1 = parsed_nq1.map(lambda r: (r[-1], ','.join(r))).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join with patents\n",
    "key_patents = patents.map(lambda r: (r[0], r[5]))\n",
    "nq2 = key_nq1.join(key_patents).cache()\n",
    "# parse and reformat\n",
    "parsed_nq2 = nq2.map(lambda r: r[1][0].split(',') + [r[1][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter rows where citing POSTATE is the same as the cited POSTATE\n",
    "nq3 = parsed_nq2.filter(lambda r: r[5]==r[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by citing PATENT\n",
    "grouped_nq3 = nq3.groupBy(lambda r: r[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count cocitations\n",
    "counted_nq3 = grouped_nq3.map(lambda r: (r[0], len(r[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make key value pairs\n",
    "key_patents = patents.map(lambda r: (r[0], ','.join(r)))\n",
    "# join with count cocitations\n",
    "nq4 = key_patents.join(counted_nq3).cache()\n",
    "# parse and reformat\n",
    "parsed_nq4 = nq4.map(lambda r: r[1][0].split(',') + [r[1][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort in descending order of cocitation counts\n",
    "sorted_nq4 = parsed_nq4.sortBy(lambda r: -r[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['5959466',\n",
       "  '1999',\n",
       "  '14515',\n",
       "  '1997',\n",
       "  '\"US\"',\n",
       "  '\"CA\"',\n",
       "  '5310',\n",
       "  '2',\n",
       "  '',\n",
       "  '326',\n",
       "  '4',\n",
       "  '46',\n",
       "  '159',\n",
       "  '0',\n",
       "  '1',\n",
       "  '',\n",
       "  '0.6186',\n",
       "  '',\n",
       "  '4.8868',\n",
       "  '0.0455',\n",
       "  '0.044',\n",
       "  '',\n",
       "  '',\n",
       "  125],\n",
       " ['5983822',\n",
       "  '1999',\n",
       "  '14564',\n",
       "  '1998',\n",
       "  '\"US\"',\n",
       "  '\"TX\"',\n",
       "  '569900',\n",
       "  '2',\n",
       "  '',\n",
       "  '114',\n",
       "  '5',\n",
       "  '55',\n",
       "  '200',\n",
       "  '0',\n",
       "  '0.995',\n",
       "  '',\n",
       "  '0.7201',\n",
       "  '',\n",
       "  '12.45',\n",
       "  '0',\n",
       "  '0',\n",
       "  '',\n",
       "  '',\n",
       "  103],\n",
       " ['6008204',\n",
       "  '1999',\n",
       "  '14606',\n",
       "  '1998',\n",
       "  '\"US\"',\n",
       "  '\"CA\"',\n",
       "  '749584',\n",
       "  '2',\n",
       "  '',\n",
       "  '514',\n",
       "  '3',\n",
       "  '31',\n",
       "  '121',\n",
       "  '0',\n",
       "  '1',\n",
       "  '',\n",
       "  '0.7415',\n",
       "  '',\n",
       "  '5',\n",
       "  '0.0085',\n",
       "  '0.0083',\n",
       "  '',\n",
       "  '',\n",
       "  100],\n",
       " ['5952345',\n",
       "  '1999',\n",
       "  '14501',\n",
       "  '1997',\n",
       "  '\"US\"',\n",
       "  '\"CA\"',\n",
       "  '749584',\n",
       "  '2',\n",
       "  '',\n",
       "  '514',\n",
       "  '3',\n",
       "  '31',\n",
       "  '118',\n",
       "  '0',\n",
       "  '1',\n",
       "  '',\n",
       "  '0.7442',\n",
       "  '',\n",
       "  '5.1102',\n",
       "  '0',\n",
       "  '0',\n",
       "  '',\n",
       "  '',\n",
       "  98],\n",
       " ['5958954',\n",
       "  '1999',\n",
       "  '14515',\n",
       "  '1997',\n",
       "  '\"US\"',\n",
       "  '\"CA\"',\n",
       "  '749584',\n",
       "  '2',\n",
       "  '',\n",
       "  '514',\n",
       "  '3',\n",
       "  '31',\n",
       "  '116',\n",
       "  '0',\n",
       "  '1',\n",
       "  '',\n",
       "  '0.7397',\n",
       "  '',\n",
       "  '5.181',\n",
       "  '0',\n",
       "  '0',\n",
       "  '',\n",
       "  '',\n",
       "  96],\n",
       " ['5998655',\n",
       "  '1999',\n",
       "  '14585',\n",
       "  '1998',\n",
       "  '\"US\"',\n",
       "  '\"CA\"',\n",
       "  '',\n",
       "  '1',\n",
       "  '',\n",
       "  '560',\n",
       "  '1',\n",
       "  '14',\n",
       "  '114',\n",
       "  '0',\n",
       "  '1',\n",
       "  '',\n",
       "  '0.7387',\n",
       "  '',\n",
       "  '5.1667',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  96],\n",
       " ['5936426',\n",
       "  '1999',\n",
       "  '14466',\n",
       "  '1997',\n",
       "  '\"US\"',\n",
       "  '\"CA\"',\n",
       "  '5310',\n",
       "  '2',\n",
       "  '',\n",
       "  '326',\n",
       "  '4',\n",
       "  '46',\n",
       "  '178',\n",
       "  '0',\n",
       "  '1',\n",
       "  '',\n",
       "  '0.58',\n",
       "  '',\n",
       "  '11.2303',\n",
       "  '0.0765',\n",
       "  '0.073',\n",
       "  '',\n",
       "  '',\n",
       "  94],\n",
       " ['5925042',\n",
       "  '1999',\n",
       "  '14445',\n",
       "  '1997',\n",
       "  '\"US\"',\n",
       "  '\"CA\"',\n",
       "  '733846',\n",
       "  '2',\n",
       "  '',\n",
       "  '606',\n",
       "  '3',\n",
       "  '32',\n",
       "  '242',\n",
       "  '0',\n",
       "  '1',\n",
       "  '',\n",
       "  '0.7382',\n",
       "  '',\n",
       "  '8.3471',\n",
       "  '0',\n",
       "  '0',\n",
       "  '',\n",
       "  '',\n",
       "  90],\n",
       " ['5913855',\n",
       "  '1999',\n",
       "  '14417',\n",
       "  '1997',\n",
       "  '\"US\"',\n",
       "  '\"CA\"',\n",
       "  '733846',\n",
       "  '2',\n",
       "  '',\n",
       "  '606',\n",
       "  '3',\n",
       "  '32',\n",
       "  '242',\n",
       "  '0',\n",
       "  '1',\n",
       "  '',\n",
       "  '0.7403',\n",
       "  '',\n",
       "  '8.3595',\n",
       "  '0',\n",
       "  '0',\n",
       "  '',\n",
       "  '',\n",
       "  90],\n",
       " ['5739256',\n",
       "  '1998',\n",
       "  '13983',\n",
       "  '1995',\n",
       "  '\"US\"',\n",
       "  '\"CA\"',\n",
       "  '70060',\n",
       "  '2',\n",
       "  '15',\n",
       "  '528',\n",
       "  '1',\n",
       "  '15',\n",
       "  '453',\n",
       "  '0',\n",
       "  '1',\n",
       "  '',\n",
       "  '0.8232',\n",
       "  '',\n",
       "  '15.1104',\n",
       "  '0.1124',\n",
       "  '0.1082',\n",
       "  '',\n",
       "  '',\n",
       "  90]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print answer\n",
    "sorted_nq4.take(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
